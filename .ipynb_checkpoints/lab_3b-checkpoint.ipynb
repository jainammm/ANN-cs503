{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ox5bZYB3DNOC"
   },
   "source": [
    "# **Lab 3 (b)**\n",
    "### Weightage 3.6%\n",
    "# Convolutional Neural Networks\n",
    "---\n",
    "Dataset used: Cats Vs. Dogs\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "Maximum Points in the Lab: 90\n",
    "\n",
    "---\n",
    "Important points to remember :\n",
    "\n",
    "\n",
    "1.  Observations for the experiments should be explained.\n",
    "2. All the code should be submitted in the form of a single Jupyter notebook itself.\n",
    "3. Points for each sub-section are mentioned in the appropriate question.\n",
    "4. Make sure to begin early as a few experiments may consume more time to run.\n",
    "5. You can use Google colab to run in jupyter notebook (https://colab.research.google.com/) How to load data in Google Colab ?(https://towardsdatascience.com/3-ways-to-load-csv-files-into-colab-7c14fcbdcb92)\n",
    "6. The lab must be submitted on Google classroom. The code as well as the accompanying observations should be made part of the python notebook.\n",
    "7. **Code Readability** is very important. Hence use self explanatory variable names and add comments to describe your approach wherever necessary.\n",
    "8. You are expected to submit your **detailed inferences** and not just an error free code.\n",
    "9. The lab is due on **March 20th 11.59pm**.\n",
    "10. The lab should be completed **individually**. Students are expected to follow the **honor code** of the class.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0N-8M76B6lbs"
   },
   "source": [
    "In this part of your Lab 3, you will be using Convolutional Neural Network to classify whether a given image contains a Cat or a Dog. You can use the tensorflow package for this implementation. The Cats and Dogs dataset from the famous Kaggle contest which is filtered and available at tensorflow can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Zll6hyd7aOj"
   },
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# If using Google Colab, use the following package to display the image\n",
    "# If running on your local system, cv2.imshow shall work fine\n",
    "# If running on your local system please comment the line below\n",
    "# from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AaeSEg-l8zmJ"
   },
   "source": [
    "# Data loading and Preprocessing\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "The following blocks downloads the dataset stored at tensorflow and extracts them to be used to train the CNN model. **Please don't make any changes to these blocks below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C1nqr-CYY6uw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
      "68608000/68606236 [==============================] - 42s 1us/step\n"
     ]
    }
   ],
   "source": [
    "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
    "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract = True)\n",
    "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Giv0wMQzVrVw"
   },
   "source": [
    "The dataset has the following directory structure:\n",
    "\n",
    "<pre>\n",
    "<b>cats_and_dogs_filtered</b>\n",
    "|__ <b>train</b>\n",
    "    |______ <b>cats</b>: [cat.0.jpg, cat.1.jpg, cat.2.jpg ....]\n",
    "    |______ <b>dogs</b>: [dog.0.jpg, dog.1.jpg, dog.2.jpg ...]\n",
    "|__ <b>validation</b>\n",
    "    |______ <b>cats</b>: [cat.2000.jpg, cat.2001.jpg, cat.2002.jpg ....]\n",
    "    |______ <b>dogs</b>: [dog.2000.jpg, dog.2001.jpg, dog.2002.jpg ...]\n",
    "</pre>\n",
    "\n",
    "Extract the paths of these directories onto different variables to facilitate accessing the dataset and thereby training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Od3pa4jM-N7G"
   },
   "outputs": [],
   "source": [
    "train_dir_path = os.path.join(PATH, 'train')\n",
    "validation_dir_path = os.path.join(PATH, 'validation')\n",
    "\n",
    "train_cats_dir_path = os.path.join(train_dir_path, 'cats')  \n",
    "train_dogs_dir_path = os.path.join(train_dir_path, 'dogs') \n",
    "validation_cats_dir_path = os.path.join(validation_dir_path, 'cats')  \n",
    "validation_dogs_dir_path = os.path.join(validation_dir_path, 'dogs')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1MiGpUuBBW0V"
   },
   "source": [
    "## Create a labelled test set from the validation set\n",
    "As you would have seen we have only training and validation sets with labels as the ground truth labels for the Kaggle contest test set images is not public. Hence we shall consider 10% of validation data (5% Cats, 5% Dogs)  as our test set. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Ayr_XJOCNSj"
   },
   "outputs": [],
   "source": [
    "# Create a test directory with the same Cats and Dogs sub directory structure \n",
    "test_dir_path = os.path.join(PATH, 'labelled_test')\n",
    "if not  os.path.exists(test_dir_path):\n",
    "    os.makedirs(test_dir_path)\n",
    "test_cats_dir_path = os.path.join(test_dir_path,'cats')\n",
    "test_dogs_dir_path = os.path.join(test_dir_path,'dogs')\n",
    "if not os.path.exists(test_cats_dir_path):\n",
    "    os.makedirs(test_cats_dir_path)\n",
    "if not os.path.exists(test_dogs_dir_path):\n",
    "    os.makedirs(test_dogs_dir_path)\n",
    "\n",
    "# Randomly pick 5% of validation Cat Images \n",
    "val_cat_list = os.listdir(validation_cats_dir_path)\n",
    "num_cat_test_files = int(0.05 * len(val_cat_list))\n",
    "chosen_cats = random.sample(val_cat_list,num_cat_test_files)\n",
    "\n",
    "# Randomly pick 5% of validation Dog Images \n",
    "val_dog_list = os.listdir(validation_dogs_dir_path)\n",
    "num_dog_test_files = int(0.05 * len(val_dog_list))\n",
    "chosen_dogs = random.sample(val_dog_list,num_dog_test_files)\n",
    "\n",
    "# Move the selected Cat Images from Validation Cats directory to Test Cats directory \n",
    "for cat in chosen_cats:\n",
    "    src_path = os.path.join(validation_cats_dir_path,cat)\n",
    "    if not os.path.exists(os.path.join(test_cats_dir_path,cat)):\n",
    "        shutil.move(src_path,test_cats_dir_path)\n",
    "\n",
    "# Move the selected Dog Images from Validation Dogs directory to Test Dogs directory \n",
    "for dog in chosen_dogs:\n",
    "    src_path = os.path.join(validation_dogs_dir_path,dog)\n",
    "    if not os.path.exists(os.path.join(test_dogs_dir_path,dog)):\n",
    "        shutil.move(src_path,test_dogs_dir_path)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N_igbd5wLynk"
   },
   "outputs": [],
   "source": [
    "num_cats_train =  len(os.listdir(train_cats_dir_path))\n",
    "num_dogs_train =  len(os.listdir(train_dogs_dir_path))\n",
    "num_cats_val =  len(os.listdir(validation_cats_dir_path))\n",
    "num_dogs_val =  len(os.listdir(validation_dogs_dir_path))\n",
    "num_cats_test =  len(os.listdir(test_cats_dir_path))\n",
    "num_dogs_test =  len(os.listdir(test_dogs_dir_path))\n",
    "\n",
    "total_train_data = num_cats_train + num_dogs_train\n",
    "total_val_data = num_cats_val + num_dogs_val\n",
    "total_test_data = num_cats_test + num_dogs_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Xcc02xp8Vt7"
   },
   "source": [
    "The images are of different sizes, but our machine learning model requires input images to be of a fixed size. Let us decide an input size 200 x 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AZ2SiCOGNQxc"
   },
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 200\n",
    "IMG_WIDTH = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Jfk6aSAVrWD"
   },
   "source": [
    "# Generate Image Batches\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "As images are high dimensional, fitting the model on entire training set may be memory and computation inefficient. Hence we generate batches of images to be processed by the model. `ImageDataGenerator` class in tensorflow facilitates this. \n",
    "\n",
    "Describe the various arguments in the instantiation of `tensorflow.keras.preprocessing.image.ImageDataGenerator` object.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "---\n",
    "\n",
    "* `featurewise_center`: To set input mean zero over dataset\n",
    "* `featurewise_std_normalization`: To divide input by std of dataset\n",
    "* `samplewise_center`: To set input mean zero over each sample\n",
    "* `samplewise_std_normalization`: To divide input by its std\n",
    "* `rotation_range`: Degree of random rotations\n",
    "* `width_shift_range`: Range of width shift\n",
    "* `height_shift_range`: Range of height shift\n",
    "* `brightness_range`: Range for picking brightness\n",
    "* `shear_range`: Range of shear intensity\n",
    "* `zoom_range`: Range of zoom\n",
    "* `fill_mode`: Fill points outside boundaries based on value\n",
    "* `horizontal_flip`: Randomly flip horizontally\n",
    "* `vertical_flip`: Randomly flip vertically\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ETEYYv3gV2PM"
   },
   "source": [
    "Describe the arguments of `flow_from_directory()` method of the `tensorflow.keras.preprocessing.image.ImageDataGenerator` object. \n",
    "\n",
    "---\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "---\n",
    "\n",
    "* `directory`: Path to directory\n",
    "* `target_size`: Size in terms of width and height to which images should be resized\n",
    "* `color_mode`: To convert images into grayscale, rgb or rgba\n",
    "* `batch_size`: Size of data\n",
    "* `seed`: Random seed \n",
    "* `shuffle`: Bool, Whether to shuffle the data\n",
    "* `interpolation`: Interpolation method to resample image\n",
    "* `class_mode`: Determines the type of label arrays returned \n",
    "* `save_to_dir`: To save the augmented images\n",
    "* `save_prefix`: Prefix used while saving the image\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yzq2aTiOQF5W"
   },
   "source": [
    "Create a function that returns a generator object which shall fetch batches of images from the specified directory. This function shall be reused for fetching images from train, validation or test directories.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yFmDipKjUKAI"
   },
   "outputs": [],
   "source": [
    "def get_generator(directory_path, batch_size_):\n",
    "    data_gen = ImageDataGenerator(\n",
    "        rescale=1./255\n",
    "    )\n",
    "    \n",
    "    data_batch_generator = data_gen.flowflow_from_directory(\n",
    "        directory = directory_path,\n",
    "        target_size = (IMG_HEIGHT, IMG_WIDTH),\n",
    "        batch_size=batch_size_,\n",
    "        class_mode=\"binary\",\n",
    "        shuffle = True,\n",
    "        seed = 107\n",
    "    )\n",
    "\n",
    "\n",
    "    return data_batch_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ELZDFQHLXc0u"
   },
   "source": [
    "Describe the arguments for the following functions callable on a `tensorflow.keras.Sequential` model object :\n",
    "\n",
    "1. add() **[5 Points]**\n",
    "\n",
    "> It adds a layer on top of layer stack\n",
    "\n",
    "* `layer`: Adds a layer instance\n",
    "\n",
    "---\n",
    "\n",
    "2. compile() **[5 Points]**\n",
    "\n",
    "> It configures the model for training\n",
    "\n",
    "* `optimizer`: optimizer instance\n",
    "* `loss`: string or objective function instance for loss\n",
    "* `metrics`: list of metrics to be evaluated by the model during training and testing, like *accuracy*\n",
    "* `loss_weights`: list or dictionary specifying scalar coefficients\n",
    "* `sample_weight_mode`: to do timestep-wise sample weighting. If model has multiple outputs, by passing a dict we can use this parameter differently for each output\n",
    "* `weighted_metrics`: list of metrics to be evaluated and weighted by sample_weight or class_weight\n",
    "* `target_tensors`: to use our own tensor targets\n",
    "* `**kwargs`: any additional args\n",
    "\n",
    "---\n",
    "\n",
    "3. fit() **[5 Points]**\n",
    "\n",
    "> Trains the model for a fixed number of epochs\n",
    "\n",
    "* `x`: input data\n",
    "* `y`: target data\n",
    "* `batch_size`: number of samples before gradient update\n",
    "* `epochs`: number of iterations to train the model\n",
    "* `verbose`: verbosity mode\n",
    "* `callbacks`: list of callback ins for training \n",
    "* `validation_split`: fraction of data used as validation data\n",
    "* `validation_data`: data to evaluate loss after end of epoch\n",
    "* `shuffle`: whether to shuffle the training data before each epoch\n",
    "* `class_weight`: dict for weighing the loss func\n",
    "* `initial_epoch`: epoch at which start the training \n",
    "* `steps_per_epoch`: number of steps before declaring one epoch is complete\n",
    "* `max_queue_size`: maximum size of generator queue \n",
    "* `use_multiprocessing`: use process based threading or not\n",
    "* `**kwargs`: for backwards compatibility\n",
    "\n",
    "---\n",
    "\n",
    "4. predict()  **[5 Points]**\n",
    "\n",
    "> Generates output for the input samples\n",
    "\n",
    "* `x`: Input samples\n",
    "* `batch_size`: number of samples per gradient update\n",
    "* `verbose`: Verbosity mode\n",
    "* `steps`: number of steps before declaring the prediction round is over\n",
    "* `callbacks`: list of callback durng prediction\n",
    "* `max_queue_size`: max size of generator queue\n",
    "* `workers`: maximum number of threads while multiprocessing\n",
    "* `use_multiprocessing`: use process based threading or not\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kYB5ayIWeDAI"
   },
   "source": [
    "Describe the arguments used when instantiating the following `tensorflow.keras.layers` :\n",
    "1. Conv2D() **[5 Points]**\n",
    "\n",
    "> This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs.\n",
    "\n",
    "* `filters`: dimension of the output space\n",
    "* `kernel_size`: height and width of 2D convolution window\n",
    "* `strides`: strides of the convolution by the height and weight\n",
    "* `padding`: *valid* or *same*\n",
    "* `data_format`: ordering of the dimensions of input\n",
    "* `dilation_rate`: rate of dilation for dilated conv\n",
    "* `activation`: activation func to use\n",
    "* `use_bias`: whether use or not bias in layer\n",
    "* `kernel_initializer`: initializer for kernel weights\n",
    "* `bias_initializer`: initializer for bias vector\n",
    "* `kernel_regularizer`: regularizer function applied to the kernel weights matrix\n",
    "* `bias_regularizer`: regularization func for bias \n",
    "* `activity_regularizer`: regularization function applied to the output of the layer\n",
    "* `kernel_constraint`: constraints for kernel weights\n",
    "* `bias_constraint`: constraints for bias vector\n",
    "\n",
    "---\n",
    "\n",
    "2. MaxPooling2D() **[5 Points]**\n",
    "\n",
    "> Max pooling operation for spatial data.\n",
    "\n",
    "* `pool_size`: factor of downscaling\n",
    "* `strides`: strides of the convolution by the height and weight\n",
    "* `padding`: *valid* or *same*\n",
    "* `data_format`: ordering of the dimensions of input\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "3. Flatten()  **[5 Points]**\n",
    "\n",
    "> Flattens the input\n",
    "\n",
    "* `data_format`: ordering of the dimensions in the inputs (*A string*)\n",
    "\n",
    "---\n",
    "\n",
    "4. Dense()  **[5 Points]**\n",
    "\n",
    "> Just a regular densely-connected NN layer\n",
    "\n",
    "* `units`: dimentionality of output\n",
    "* `activation`: activation func to use\n",
    "* `use_bias`: whether use or not bias in layer\n",
    "* `kernel_initializer`: initializer for kernel weights\n",
    "* `bias_initializer`: initializer for bias vector\n",
    "* `kernel_regularizer`: regularizer function applied to the kernel weights matrix\n",
    "* `bias_regularizer`: regularization func for bias \n",
    "* `activity_regularizer`: regularization function applied to the output of the layer\n",
    "* `kernel_constraint`: constraints for kernel weights\n",
    "* `bias_constraint`: constraints for bias vector\n",
    "\n",
    "---\n",
    "\n",
    "5. Dropout() **[5 Points]**\n",
    "\n",
    "> Applies Dropout to the input\n",
    "\n",
    "* `rate`: fraction of the input units to drop\n",
    "* `noise_shape`: shape for binary dropout mask that will be multiplied with the input\n",
    "* `seed`: random seed\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qBJ8h0Hufc1c"
   },
   "source": [
    "# Defining the model architecture\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "We have defined our CNN model architecture here. **Please dont make any changes to the two blocks below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vkvOchLWbcja"
   },
   "outputs": [],
   "source": [
    "def build_cnn_model(dropout_probability = 0):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT,IMG_WIDTH, 3)))\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(dropout_probability))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HUvI6r9ZK2XP"
   },
   "outputs": [],
   "source": [
    "#  Variables needed for subsequent sections\n",
    "\n",
    "num_epochs = 5\n",
    "# In binary mode cat is encoded as 0 and dog as 1. The below list shall be used to decode in order to get a human readable label.\n",
    "labels = [\"Cat\",\"Dog\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bKEeQaIDhTHF"
   },
   "source": [
    "# Best Batch size determination\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "Now we are ready to start working with the model. The hyperparameters we would like you to experiment are batch size and dropout probability. We shall start with the  experimentation of **batch size**. Discuss the impact of batch size on model training and performance.\n",
    "\n",
    "\n",
    "---\n",
    "**5 Points**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "onL3EKgc6wYk"
   },
   "outputs": [],
   "source": [
    "def determine_best_batch_size():\n",
    "    batch_sizes = [16,32,64]\n",
    "    # 32\n",
    "    avg_val_accuracies = []\n",
    "\n",
    "    # Insert your code here to build a CNN model with the default dropout probability\n",
    "    model = build_cnn_model()\n",
    "\n",
    "    for bsize in batch_sizes:\n",
    "        \n",
    "        # Insert your code here to get generators that fetch batches from train and validation directories as per current batch size\n",
    "        training_generators = get_generator(train_dir_path, bsize)\n",
    "        validation_data_generators = get_generator(validation_dir_path, bsize)\n",
    "        \n",
    "        #step per epoch ko bada number rakhna\n",
    "        # Insert your code here to train the CNN model using the training set and validate using the validation set\n",
    "        model.fit(x = training_generators,\n",
    "                validation_data=validation_generator,\n",
    "                batch_size = bsize,\n",
    "                epochs = num_epochs,\n",
    "                shuffle = True,\n",
    "                steps_per_epoch = 1000000,\n",
    "                use_multiprocessing = True\n",
    "                )\n",
    "        \n",
    "        # Insert your code here to find the average validation accuracy for this model setting and append it to the maintained list\n",
    "        \n",
    "\n",
    "    # Insert your code here to figure out the batch size which gives the highest average validation accuracy. Print the value and return it.\n",
    "    maxAccuracyBatch = batch_sizes[avg_val_accuracies.index(max(avg_val_accuracies))]\n",
    "    print (f\"The best batch size is {maxAccuracyBatch}\" )\n",
    "    return maxAccuracyBatch\n",
    "\n",
    "\n",
    "# determine_best_batch_size() is being called here\n",
    "best_batch_size = determine_best_batch_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e6Srd64UL8Ef"
   },
   "source": [
    "# Best Dropout Probability determination\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Use the best batch size determined in the previous section for the subsequent sections. We shall now do experimentation of **dropout probability** parameter. Discuss the impact of dropout probability on model performance.\n",
    "\n",
    "\n",
    "---\n",
    "**5 Points**\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FUEB-EDKNpxE"
   },
   "outputs": [],
   "source": [
    "def determine_best_dropout_probability():\n",
    "    dropout_probs = [0,0.25,0.5,0.75]\n",
    "    avg_val_accuracies = []\n",
    "\n",
    "\n",
    "    # Insert your code here to get generators that fetch batches from train and validation directories as per best batch size\n",
    "    \n",
    "\n",
    "    for prob in dropout_probs:\n",
    "        \n",
    "        \n",
    "        # Insert your code here to build a CNN model with the current dropout probability\n",
    "        \n",
    "\n",
    "        # Insert your code here to train the CNN model using the training set and validate using the validation set\n",
    "        \n",
    "       \n",
    "        # Insert your code here to find average validation accuracy for this model setting and append it to the maintained list\n",
    "        \n",
    "\n",
    "    # Insert your code here to figure out the dropout probability which gives the highest average validation accuracy. Print the value and return it.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# determine_best_dropout_probability() is being called here\n",
    "best_prob = determine_best_dropout_probability()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5ZJ1YjC9OpKg"
   },
   "source": [
    "# Images Visualization\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Now we shall train our CNN model with best hyperparameters. As a first step we need to plot images to have visual understanding of the data. This image visualization shall be reused. Hence create a custom **function to visualize images**.\n",
    "\n",
    "\n",
    "---\n",
    "**2 Points**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3lhg_JrXZFzJ"
   },
   "outputs": [],
   "source": [
    "def visualize_image(img):\n",
    "    # Insert your code here to visualize a given image\n",
    "    # cv2_imshow\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8qmRP8AYZ8O5"
   },
   "source": [
    "# Make generators ready\n",
    "\n",
    "---\n",
    "\n",
    "Create generators to fetch batches from train, test and validation directories. You may use best batch size determined earlier.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "**3 Points**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hXHbxHWSZ4kS"
   },
   "outputs": [],
   "source": [
    "# Insert your code here to create generators that fetch batches of size best_batch_size (determined earlier) from train, validation and test directories\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yJu763mjzqVP"
   },
   "source": [
    "# Visualize training images\n",
    "\n",
    "---\n",
    "\n",
    "To get an understanding of the data fetch a training batch and visualize any 5 training images along with their labels. \n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**Note**: In binary mode, ImageDataGenerator encodes Cats as 0 and Dogs as 1.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**2 Points**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QGG9SqQ70RtP"
   },
   "outputs": [],
   "source": [
    "# Insert your code here to obtain a sample training images batch from the train directory generator\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    # Insert your code here to visualize the training images\n",
    "    \n",
    "    \n",
    "    # Insert your code here to print corresponding training label: Cat / Dog\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jjyJpqPJdo1N"
   },
   "source": [
    "# Build Model\n",
    "\n",
    "---\n",
    "Now build the model as per the best dropout probability value determined earlier. Summarize the model architecture.\n",
    "\n",
    "---\n",
    "\n",
    "**2 Points**\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3lnXy6PZfhSC"
   },
   "outputs": [],
   "source": [
    "# Insert your code here to build the CNN model as per the best dropout probability value determined earlier\n",
    "\n",
    "\n",
    "# Insert your code here to print the model summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xqekZRlBr5WE"
   },
   "source": [
    "# Training the Model\n",
    "\n",
    "---\n",
    "Train the model built with best hyperparameter settings. Generate a **Plot** of Epochs Vs. training and validation accuracy. Also generate a similar plot for training and validation loss. Discuss your **inferences** from the plot.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**7 Points**\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uBM4OVXNs8Br"
   },
   "outputs": [],
   "source": [
    "# Insert your code here to train the CNN model with best hyperparameter settings using training set and validate using the validation set (1 Point)\n",
    "\n",
    "\n",
    "# Insert your code here to obtain the lists: epochs, training accuracy, validation accuracy, training loss, validation loss (2 Points)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Insert your code here to plot Epochs Vs. training and validation accuracy (2 Points)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Insert your code here to plot Epochs Vs. training and validation loss (2 Points)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OO87N5Iv5aoq"
   },
   "source": [
    "# Prediction\n",
    "\n",
    "---\n",
    "Fetch a sample test batch and determine the model's predictions on this batch of test images. Generate a confusion matrix and comment on the prediction statistics.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**Note**: Predictions would return the probability of the image belonging to class 1 (Dog). If this value is more than 0.5, assign class 1 (Dog) as the prediction. Else, assign class 0(Cat) as the prediction.\n",
    "\n",
    "---\n",
    "**2 Points**\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EqKv23bx7z16"
   },
   "outputs": [],
   "source": [
    "# Insert your code here to obtain a sample test images batch from the test directory generator\n",
    "\n",
    "\n",
    "# Insert your code here to get the model's prediction probabilities\n",
    "\n",
    "\n",
    "# Insert your code here to assign class label based on prediction probabilities\n",
    "\n",
    "\n",
    "# Insert your code here to print the confusion matrix.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GQwgrYEEAF3V"
   },
   "source": [
    "Discuss the **inferences** you obtained from the confusion matrix.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**2 Points**\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lab_3b_cnn.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
